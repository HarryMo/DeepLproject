{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech_to_text_deeplearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2o8fnHeSD6c",
        "colab_type": "code",
        "outputId": "29d4d302-9b74-4e90-de88-4f08b06a91e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "source": [
        "useColab=True\n",
        "if useColab:\n",
        "    %tensorflow_version 2.x\n",
        "    !wget -q https://raw.githubusercontent.com/douglas125/SpeechCmdRecognition/master/SpeechDownloader.py\n",
        "    !wget -q https://raw.githubusercontent.com/douglas125/SpeechCmdRecognition/master/SpeechGenerator.py\n",
        "    !wget -q https://raw.githubusercontent.com/douglas125/SpeechCmdRecognition/master/requirements.txt\n",
        "    !pip install -r requirements.txt"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow>=2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (2.2.0rc1)\n",
            "Requirement already satisfied: kapre>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.1.7)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.25.3)\n",
            "Requirement already satisfied: librosa>=0.6 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (4.38.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (3.2.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (1.18.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (2.2.0rc0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (1.27.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (2.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (0.34.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (2.1.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2->-r requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.25->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.25->-r requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.6->-r requirements.txt (line 4)) (0.47.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.6->-r requirements.txt (line 4)) (0.22.2.post1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.6->-r requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.6->-r requirements.txt (line 4)) (0.14.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.6->-r requirements.txt (line 4)) (2.1.8)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.6->-r requirements.txt (line 4)) (0.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 6)) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow>=2->-r requirements.txt (line 1)) (46.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2->-r requirements.txt (line 1)) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2->-r requirements.txt (line 1)) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2->-r requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2->-r requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: llvmlite>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa>=0.6->-r requirements.txt (line 4)) (0.31.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2->-r requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2->-r requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2->-r requirements.txt (line 1)) (4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2->-r requirements.txt (line 1)) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2->-r requirements.txt (line 1)) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2->-r requirements.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2->-r requirements.txt (line 1)) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7HLudcCTMDP",
        "colab_type": "text"
      },
      "source": [
        "###**Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vWRHX26SjOQ",
        "colab_type": "code",
        "outputId": "33840774-2b54-4f9e-dc47-9a0697b8b1d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 17439495806137125493\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 16052332161935604673\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcOZ-bnrSu68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa\n",
        "import keras\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "#import SpeechDownloader\n",
        "#import SpeechGenerator\n",
        "\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "import math\n",
        "import os\n",
        "import tarfile\n",
        "import librosa\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#Libraries for the model \n",
        "\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "\n",
        "from tensorflow.keras import layers as L\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "from kapre.time_frequency import Melspectrogram, Spectrogram\n",
        "from kapre.utils import Normalization2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3zvhqXq4lh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vejv7l1GTTrx",
        "colab_type": "text"
      },
      "source": [
        "##**Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvfOxEUWS-FU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def WAV2Numpy(folder, sr=None):\n",
        "    \"\"\"\n",
        "    Recursively converts WAV to numpy arrays.\n",
        "    Deletes the WAV files in the process\n",
        "    folder - folder to convert.\n",
        "    \"\"\"\n",
        "    allFiles = []\n",
        "    for root, dirs, files in os.walk(folder):\n",
        "        allFiles += [os.path.join(root, f) for f in files\n",
        "                     if f.endswith('.wav')]\n",
        "\n",
        "    for file in tqdm(allFiles):\n",
        "        y, sr = librosa.load(file, sr=None)\n",
        "\n",
        "        # if we want to write the file later\n",
        "        # librosa.output.write_wav('file.wav', y, sr, norm=False)\n",
        "        np.save(file + '.npy', y)\n",
        "        os.remove(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAkUnV0yTgg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PrepareGoogleSpeechCmd(version=2, forceDownload=False, task='20cmd'):\n",
        "    \"\"\"\n",
        "    Prepares Google Speech commands dataset version 2 for use\n",
        "    tasks: 12cmd\n",
        "    Returns full path to training, validation and test file list and file categories\n",
        "    \"\"\"\n",
        "    allowedTasks = ['12cmd'] #to be deleted at the end (vamos a supprimar)\n",
        "    if task not in allowedTasks:\n",
        "        raise Exception('Task must be one of: {}'.format(allowedTasks))\n",
        "\n",
        "    basePath = None\n",
        "    if version == 2:\n",
        "        _DownloadGoogleSpeechCmdV2(forceDownload)\n",
        "        basePath = 'sd_GSCmdV2'\n",
        "    elif version == 1:\n",
        "        _DownloadGoogleSpeechCmdV1(forceDownload)\n",
        "        basePath = 'sd_GSCmdV1'\n",
        "    else:\n",
        "        raise Exception('Version must be 1 or 2')\n",
        "#tout ça c'est to be deleted at the end\n",
        "\n",
        "    if task == '12cmd':\n",
        "        GSCmdV2Categs = {\n",
        "            'unknown': 0,\n",
        "            'silence': 1,\n",
        "            '_unknown_': 0,\n",
        "            '_silence_': 1,\n",
        "            '_background_noise_': 1,\n",
        "            'yes': 2,\n",
        "            'no': 3,\n",
        "            'up': 4,\n",
        "            'down': 5,\n",
        "            'left': 6,\n",
        "            'right': 7,\n",
        "            'on': 8,\n",
        "            'off': 9,\n",
        "            'stop': 10,\n",
        "            'go': 11}\n",
        "        numGSCmdV2Categs = 12\n",
        "\n",
        "    print('Converting test set WAVs to numpy files')\n",
        "    WAV2Numpy(basePath + '/test/')\n",
        "    print('Converting training set WAVs to numpy files')\n",
        "    WAV2Numpy(basePath + '/train/')\n",
        "\n",
        "    # read split from files and all files in folders\n",
        "    testWAVs = pd.read_csv(basePath + '/train/testing_list.txt',\n",
        "                           sep=\" \", header=None)[0].tolist()\n",
        "    valWAVs = pd.read_csv(basePath + '/train/validation_list.txt',\n",
        "                          sep=\" \", header=None)[0].tolist()\n",
        "\n",
        "    testWAVs = [os.path.join(basePath + '/train/', f + '.npy')\n",
        "                for f in testWAVs if f.endswith('.wav')]\n",
        "    valWAVs = [os.path.join(basePath + '/train/', f + '.npy')\n",
        "               for f in valWAVs if f.endswith('.wav')]\n",
        "    allWAVs = []\n",
        "    for root, dirs, files in os.walk(basePath + '/train/'):\n",
        "        allWAVs += [root + '/' + f for f in files if f.endswith('.wav.npy')]\n",
        "    trainWAVs = list(set(allWAVs) - set(valWAVs) - set(testWAVs))\n",
        "\n",
        "    testWAVsREAL = []\n",
        "    for root, dirs, files in os.walk(basePath + '/test/'):\n",
        "        testWAVsREAL += [root + '/' +\n",
        "                         f for f in files if f.endswith('.wav.npy')]\n",
        "\n",
        "    # get categories\n",
        "    testWAVlabels = [_getFileCategory(f, GSCmdV2Categs) for f in testWAVs]\n",
        "    valWAVlabels = [_getFileCategory(f, GSCmdV2Categs) for f in valWAVs]\n",
        "    trainWAVlabels = [_getFileCategory(f, GSCmdV2Categs) for f in trainWAVs]\n",
        "    testWAVREALlabels = [_getFileCategory(f, GSCmdV2Categs)\n",
        "                         for f in testWAVsREAL]\n",
        "\n",
        "    # background noise should be used for validation as well\n",
        "    backNoiseFiles = [trainWAVs[i] for i in range(len(trainWAVlabels))\n",
        "                      if trainWAVlabels[i] == GSCmdV2Categs['silence']]\n",
        "    backNoiseCats = [GSCmdV2Categs['silence']\n",
        "                     for i in range(len(backNoiseFiles))]\n",
        "    if numGSCmdV2Categs == 12:\n",
        "        valWAVs += backNoiseFiles\n",
        "        valWAVlabels += backNoiseCats\n",
        "\n",
        "    # build dictionaries\n",
        "    testWAVlabelsDict = dict(zip(testWAVs, testWAVlabels))\n",
        "    valWAVlabelsDict = dict(zip(valWAVs, valWAVlabels))\n",
        "    trainWAVlabelsDict = dict(zip(trainWAVs, trainWAVlabels))\n",
        "    testWAVREALlabelsDict = dict(zip(testWAVsREAL, testWAVREALlabels))\n",
        "\n",
        "    # a tweak here: we will heavily underuse silence samples because there are few files.\n",
        "    # we can add them to the training list to reuse them multiple times\n",
        "    # note that since we already added the files to the label dicts we don't\n",
        "    # need to do it again\n",
        "\n",
        "    # for i in range(200):\n",
        "    #     trainWAVs = trainWAVs + backNoiseFiles\n",
        "\n",
        "    # info dictionary\n",
        "    trainInfo = {'files': trainWAVs, 'labels': trainWAVlabelsDict}\n",
        "    valInfo = {'files': valWAVs, 'labels': valWAVlabelsDict}\n",
        "    testInfo = {'files': testWAVs, 'labels': testWAVlabelsDict}\n",
        "    testREALInfo = {'files': testWAVsREAL, 'labels': testWAVREALlabelsDict}\n",
        "    gscInfo = {'train': trainInfo,\n",
        "               'test': testInfo,\n",
        "               'val': valInfo,\n",
        "               'testREAL': testREALInfo}\n",
        "\n",
        "    print('Done preparing Google Speech commands dataset version {}'.format(version))\n",
        "\n",
        "    return gscInfo, numGSCmdV2Categs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cm7EOOsV-UX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def _getFileCategory(file, catDict):\n",
        "    \"\"\"\n",
        "    Receives a file with name sd_GSCmdV2/train/<cat>/<filename> and returns an integer that is catDict[cat]\n",
        "    \"\"\"\n",
        "    categ = os.path.basename(os.path.dirname(file))\n",
        "    return catDict.get(categ, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KORUGeB9X_Kl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _DownloadGoogleSpeechCmdV2(forceDownload=False):\n",
        "    \"\"\"\n",
        "    Downloads Google Speech commands dataset version 2\n",
        "    \"\"\"\n",
        "    if os.path.isdir(\"sd_GSCmdV2/\") and not forceDownload:\n",
        "        print('Google Speech commands dataset version 2 already exists. Skipping download.')\n",
        "    else:\n",
        "        if not os.path.exists(\"sd_GSCmdV2/\"):\n",
        "            os.makedirs(\"sd_GSCmdV2/\")\n",
        "        trainFiles = 'http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz'\n",
        "        testFiles = 'http://download.tensorflow.org/data/speech_commands_test_set_v0.02.tar.gz'\n",
        "        _downloadFile(testFiles, 'sd_GSCmdV2/test.tar.gz')\n",
        "        _downloadFile(trainFiles, 'sd_GSCmdV2/train.tar.gz')\n",
        "\n",
        "    # extract files\n",
        "    if not os.path.isdir(\"sd_GSCmdV2/test/\"):\n",
        "        _extractTar('sd_GSCmdV2/test.tar.gz', 'sd_GSCmdV2/test/')\n",
        "\n",
        "    if not os.path.isdir(\"sd_GSCmdV2/train/\"):\n",
        "        _extractTar('sd_GSCmdV2/train.tar.gz', 'sd_GSCmdV2/train/')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3pZSJyvYF3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _downloadFile(url, fName):\n",
        "    # Streaming, so we can iterate over the response.\n",
        "    r = requests.get(url, stream=True)\n",
        "\n",
        "    # Total size in bytes.\n",
        "    total_size = int(r.headers.get('content-length', 0))\n",
        "    block_size = 1024\n",
        "    wrote = 0\n",
        "    print('Downloading {} into {}'.format(url, fName))\n",
        "    with open(fName, 'wb') as f:\n",
        "        for data in tqdm(r.iter_content(block_size),\n",
        "                         total=math.ceil(total_size // block_size),\n",
        "                         unit='KB',\n",
        "                         unit_scale=True):\n",
        "            wrote = wrote + len(data)\n",
        "            f.write(data)\n",
        "    if total_size != 0 and wrote != total_size:\n",
        "        print(\"ERROR, something went wrong\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIPEHAyDYJzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _extractTar(fname, folder):\n",
        "    print('Extracting {} into {}'.format(fname, folder))\n",
        "    if (fname.endswith(\"tar.gz\")):\n",
        "        tar = tarfile.open(fname, \"r:gz\")\n",
        "        tar.extractall(path=folder)\n",
        "        tar.close()\n",
        "    elif (fname.endswith(\"tar\")):\n",
        "        tar = tarfile.open(fname, \"r:\")\n",
        "        tar.extractall(path=folder)\n",
        "        tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQLEFGepYKPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6SPLXcIYjcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
        "                 n_classes=10, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            X[i,] = np.load('data/' + ID + '.npy')\n",
        "\n",
        "            # Store class\n",
        "            y[i] = self.labels[ID]\n",
        "\n",
        "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2gQfupzY9V5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ConvSpeechModel(nCategories, samplingrate=16000, inputLength=16000):\n",
        "    \"\"\"\n",
        "    Base fully convolutional model for speech recognition\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = L.Input((inputLength,))\n",
        "\n",
        "    x = L.Reshape((1, -1))(inputs)\n",
        "\n",
        "    x = Melspectrogram(n_dft=1024, n_hop=128, input_shape=(1, inputLength),\n",
        "                       padding='same', sr=samplingrate, n_mels=80,\n",
        "                       fmin=40.0, fmax=samplingrate / 2, power_melgram=1.0,\n",
        "                       return_decibel_melgram=True, trainable_fb=False,\n",
        "                       trainable_kernel=False,\n",
        "                       name='mel_stft')(x)\n",
        "\n",
        "    x = Normalization2D(int_axis=0)(x)\n",
        "    # note that Melspectrogram puts the sequence in shape (batch_size, melDim, timeSteps, 1)\n",
        "    # we would rather have it the other way around for LSTMs\n",
        "\n",
        "    x = L.Permute((2, 1, 3))(x)\n",
        "    # x = Reshape((94,80)) (x) #this is strange - but now we have (batch_size,\n",
        "    # sequence, vec_dim)\n",
        "\n",
        "    c1 = L.Conv2D(20, (5, 1), activation='relu', padding='same')(x)\n",
        "    c1 = L.BatchNormalization()(c1)\n",
        "    p1 = L.MaxPooling2D((2, 1))(c1)\n",
        "    p1 = L.Dropout(0.03)(p1)\n",
        "\n",
        "    c2 = L.Conv2D(40, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = L.BatchNormalization()(c2)\n",
        "    p2 = L.MaxPooling2D((2, 2))(c2)\n",
        "    p2 = L.Dropout(0.01)(p2)\n",
        "\n",
        "    c3 = L.Conv2D(80, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = L.BatchNormalization()(c3)\n",
        "    p3 = L.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    p3 = L.Flatten()(p3)\n",
        "    p3 = L.Dense(64, activation='relu')(p3)\n",
        "    p3 = L.Dense(32, activation='relu')(p3)\n",
        "\n",
        "    output = L.Dense(nCategories, activation='softmax')(p3)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[output], name='ConvSpeechModel')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDgU1Z7m4wyR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "f9137bae-0646-43c4-c4fa-39ffa609893a"
      },
      "source": [
        "# Download and prepare all data\n",
        "gscInfo, nCategs = PrepareGoogleSpeechCmd(version=2, task = '12cmd')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  4%|▎         | 4.10k/110k [00:00<00:03, 33.0kKB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://download.tensorflow.org/data/speech_commands_test_set_v0.02.tar.gz into sd_GSCmdV2/test.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "110kKB [00:01, 86.4kKB/s]                          \n",
            "  0%|          | 4.10k/2.37M [00:00<01:29, 26.6kKB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz into sd_GSCmdV2/train.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2.37MKB [00:41, 57.7kKB/s]                           \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting sd_GSCmdV2/test.tar.gz into sd_GSCmdV2/test/\n",
            "Extracting sd_GSCmdV2/train.tar.gz into sd_GSCmdV2/train/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4890 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Converting test set WAVs to numpy files\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4890/4890 [09:58<00:00,  8.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Converting training set WAVs to numpy files\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 60358/105835 [2:05:27<1:29:11,  8.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-2577ae0a0516>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgscInfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnCategs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrepareGoogleSpeechCmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'12cmd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-7fd006e0d001>\u001b[0m in \u001b[0;36mPrepareGoogleSpeechCmd\u001b[0;34m(version, forceDownload, task)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mWAV2Numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasePath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/test/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Converting training set WAVs to numpy files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mWAV2Numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasePath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/train/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# read split from files and all files in folders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-574dde1b1ff9>\u001b[0m in \u001b[0;36mWAV2Numpy\u001b[0;34m(folder, sr)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallFiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# if we want to write the file later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbackends\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mbackends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavailable_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36mavailable_backends\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Core Audio.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_ca_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmacca\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmacca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtAudioFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36m_ca_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \"\"\"\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AudioToolbox'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ctypes/util.py\u001b[0m in \u001b[0;36mfind_library\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfind_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;31m# See issue #9998\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_findSoname_ldconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m                    \u001b[0m_get_soname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_findLib_gcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_findLib_ld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ctypes/util.py\u001b[0m in \u001b[0;36m_findSoname_ldconfig\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    280\u001b[0m                                       \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVNULL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                                       \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                                       env={'LC_ALL': 'C', 'LANG': 'C'}) as p:\n\u001b[0m\u001b[1;32m    283\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    727\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                             \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                             \u001b[0merrpipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrpipe_write\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                             restore_signals, start_new_session, preexec_fn)\n\u001b[0m\u001b[1;32m   1296\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_child_created\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of3U9YKp5Fd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}